{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(r'C:\\Users\\admin\\medical_data_saved\\drugs\\crawled\\raw.json')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['chemicals_length'] = df['chemicals'].str.len()\n",
    "print(df['chemicals_length'].describe())\n",
    "\n",
    "long_chemicals = df[df['chemicals_length'] > 2000][['drug_name', 'chemicals', 'chemicals_length']]\n",
    "long_chemicals.value_counts().sum()\n",
    "print(long_chemicals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df[['drug_name', 'chemicals']].copy()\n",
    "print(sub_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "def clean_chemicals(text, drug_name=None):\n",
    "    if pd.isna(text):\n",
    "        return pd.NA\n",
    "\n",
    "    text = unicodedata.normalize('NFKC', str(text)).lower()\n",
    "\n",
    "    text = re.sub(r'1\\s*thành phần\\s*:?', '', text)\n",
    "    text = re.sub(r'(thành phần\\s*:?\\s*){1,2}', '', text)\n",
    "\n",
    "    text = re.sub(r'\\bmỗi\\s*(viên|viên nén|viên nang|viên thuốc|lọ|ống|chai|gói|ml)?\\s*(thuốc|sản phẩm)?\\b', '', text)\n",
    "\n",
    "    text = re.sub(r'(là thuốc gì.*|thuốc gì.*|cách dùng.*|thuốc này.*|câu hỏi.*|chỉ định.*|sử dụng.*)', '', text)\n",
    "\n",
    "    if drug_name:\n",
    "        drug_name_norm = unicodedata.normalize('NFKC', str(drug_name)).lower()\n",
    "        text = re.sub(re.escape(drug_name_norm), '', text)\n",
    "\n",
    "    stopwords = [\n",
    "        'thành phần', 'thuốc', 'gói', 'ống', 'lọ', 'nén', 'nang',\n",
    "        'bao phim', 'bao chế', 'dưới dạng', 'hàm lượng', 'được dùng', 'được',\n",
    "        'bao gồm', 'là', 'chứa', 'tá dược.*', 'vừa đủ.*',\n",
    "        'trong', 'sản phẩm', 'của', 'dạng', 'với'\n",
    "    ]\n",
    "    \n",
    "    pattern_stopwords = r'\\b(' + '|'.join(stopwords) + r')\\b'\n",
    "    text = re.sub(pattern_stopwords, '', text)\n",
    "\n",
    "    text = re.sub(r'[^\\w\\s%/.,μgmgmlmcgiu]', ' ', text)\n",
    "\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# Áp dụng\n",
    "sub_df['chemicals'] = sub_df['chemicals'].apply(clean_chemicals)\n",
    "sub_df['drug_name'] = sub_df['drug_name'].apply(clean_chemicals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df['chemicals_length'] = sub_df['chemicals'].str.len()\n",
    "print(sub_df['chemicals_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_chemicals = sub_df[sub_df['chemicals_length'] > 2000][['drug_name', 'chemicals', 'chemicals_length']]\n",
    "long_chemicals.value_counts().sum()\n",
    "print(long_chemicals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_chemicals(text, drug_name=None):\n",
    "    if pd.isna(text) or not isinstance(text, str) or len(text.strip()) == 0:\n",
    "        return [{'ingredient': '', 'dose': None}]\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    if isinstance(drug_name, str) and len(drug_name.strip()) > 0:\n",
    "        drug_name = drug_name.lower()\n",
    "        text = re.sub(re.escape(drug_name), '', text)\n",
    "    \n",
    "    units = r'mg|g|mcg|μg|ml|m\\s?ui|iu|%|mg/ml|g/ml|iu/ml'\n",
    "    dose_pattern = rf'(?:\\d+(?:[\\.,]\\d+)?(?:\\s*/\\s*\\d+(?:[\\.,]\\d+)?\\s*)?(?:\\s*(?:{units}))?)'\n",
    "\n",
    "    matches = re.findall(\n",
    "        rf'([a-zàáạảãâầấậẩẫăằắặẳẵêềếệểễèéẹẻẽôồốộổỗơờớợởỡưừứựửữùúụủũìíịỉĩỳýỵỷỹđ\\s\\-]+?)\\s*({dose_pattern})',\n",
    "        text\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    for ing, dose in matches:\n",
    "        ing = re.sub(r'\\s+', ' ', ing.strip())\n",
    "        dose = dose.replace(',', '.').replace(' ', '')\n",
    "        results.append({'ingredient': ing, 'dose': dose})\n",
    "    \n",
    "    if not results:\n",
    "        short = text.split('.')[0].split('\\n')[0][:40]\n",
    "        return [{'ingredient': short.strip(), 'dose': None}]\n",
    "    \n",
    "    return results\n",
    "\n",
    "sub_df['chemicals'] = sub_df['chemicals'].apply(extract_chemicals)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_pics = pd.DataFrame({\n",
    "    'path': [\n",
    "        r\"C:\\Users\\admin\\Documents\\data\\.data\\20231213145107_001.pdf.0000.png\",\n",
    "        r\"C:\\Users\\admin\\Documents\\data\\.data\\20140119215734_001.pdf.0000.png\",\n",
    "        r\"C:\\Users\\admin\\Documents\\data\\.data\\a8e7c9eca5b61ee847a7.jpg.0000.png\"\n",
    "    ],\n",
    "    'ocr_text': [\n",
    "        [\n",
    "            \"Ibandronic Acid (Jointmeno) 150mg – Viên uống, 1 viên/tháng, dùng buổi sáng, uống với ~150ml nước, không ăn/uống thêm trong 1h\",\n",
    "            \"NextG Cal 500mg – Viên uống, 2 viên/trưa, 30 ngày, tổng liều 60 viên\"\n",
    "        ],\n",
    "        [\n",
    "            \"Levofloxacin (LEVODHG 500) 500mg – Viên, tổng 14 viên (2 viên/ngày, sáng-tối, 7 ngày)\",\n",
    "            \"Diosmin + hesperidin (Venokern 500mg) 450mg + 50mg – Viên, 60 viên (6 viên/ngày đầu chia 3 lần, sau uống 4 viên/ngày chia 2 lần)\"\n",
    "        ],\n",
    "        [\n",
    "            \"Bình vị nam - Việt Nam – 300 viên (uống 10 viên/ngày, 5 sáng, 5 tối)\",\n",
    "            \"Modom'S (Domperidone 10mg) – 60 viên (2 viên/ngày, sáng-tối, 1 viên/lần)\",\n",
    "            \"Hacumin (Nano Curcumin, Royal Jelly) – 60 viên (2 viên/ngày, sáng-tối)\",\n",
    "            \"Somastop (Sucralfat) – 60 viên (2 viên/ngày, sáng-tối)\",\n",
    "            \"Repratt (Pantoprazol 40mg) – 60 viên (2 viên/ngày, sáng-tối)\"\n",
    "        ]\n",
    "    ]\n",
    "})\n",
    "\n",
    "df_pics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz\n",
    "from plasma.meta.class_registrator import ObjectFactory\n",
    "from typing import Callable\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "matcher_factory = ObjectFactory[str, Callable[[str, pd.DataFrame], pd.Series]]()\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = unicodedata.normalize('NFD', str(text))\n",
    "    text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "def split_ocr_lines(lines: list[str]):\n",
    "    split_lines = []\n",
    "    units = r'(mg|ml|vien|goi|vi)'\n",
    "    for line in lines:\n",
    "        marked = re.sub(rf'{units}', r'\\1||', line, flags=re.IGNORECASE)\n",
    "        parts = marked.split('||')\n",
    "        split_lines.extend([p.strip() for p in parts if len(p.strip()) > 5])\n",
    "    return split_lines\n",
    "\n",
    "sub_df['norm_name'] = sub_df['drug_name'].apply(normalize_text)\n",
    "drug_keywords = set(sub_df['norm_name'].tolist())\n",
    "\n",
    "def filter_relevant_lines(lines):\n",
    "    return [l for l in lines if any(kw in normalize_text(l) for kw in drug_keywords)]\n",
    "\n",
    "@matcher_factory.register(\"fuzzy\")\n",
    "def fuzzy_match(line: str, sub_df: pd.DataFrame):\n",
    "    norm_line = normalize_text(line)\n",
    "    best_score, best_row = 0, None\n",
    "    for _, row in sub_df.iterrows():\n",
    "        name = normalize_text(row['drug_name'])\n",
    "        score = fuzz.partial_ratio(norm_line, name)\n",
    "        if score > best_score and score > 92 and name in norm_line:\n",
    "            best_score, best_row = score, row\n",
    "    return best_row\n",
    "\n",
    "def classify_medicine_lines(lines: list[str], sub_df: pd.DataFrame, method=\"fuzzy\"):\n",
    "    matcher = matcher_factory[method]\n",
    "    results = []\n",
    "    for line in lines:\n",
    "        row = matcher(line, sub_df)\n",
    "        if row is not None:\n",
    "            results.append({\n",
    "                \"matched_name\": row['drug_name'],\n",
    "                \"chemicals\": row['chemicals']\n",
    "            })\n",
    "    return results if results else None\n",
    "\n",
    "df_pics['ocr_lines'] = df_pics['ocr_text'].apply(split_ocr_lines)\n",
    "df_pics['ocr_filtered'] = df_pics['ocr_lines'].apply(filter_relevant_lines)\n",
    "df_pics['matched'] = df_pics['ocr_filtered'].apply(\n",
    "    lambda lines: classify_medicine_lines(lines, sub_df, method=\"fuzzy\")\n",
    ")\n",
    "\n",
    "for idx, row in df_pics.iterrows():\n",
    "    print(f'CASE {idx + 1} | {row.get(\"path\", \"unknown\")}')\n",
    "    print(\"OCR lines:\", row['ocr_lines'])\n",
    "    print(\"Matched:\", [{m['matched_name']: m['chemicals']} for m in row['matched']] if row['matched'] else \"No match\")\n",
    "\n",
    "print(df_pics[['ocr_text', 'matched']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import easyocr\n",
    "import re\n",
    "\n",
    "df_pics = pd.read_pickle(r\"C:\\Users\\admin\\Documents\\data\\data.pkl\")\n",
    "base_path = r\"C:\\Users\\admin\\Documents\\data\\.data\"\n",
    "df_pics['abs_path'] = df_pics['path'].apply(lambda p: os.path.join(base_path, os.path.basename(p)))\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    img = cv2.resize(img, None, fx=2.0, fy=2.0, interpolation=cv2.INTER_LINEAR)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    contrast = clahe.apply(gray)\n",
    "    blur = cv2.GaussianBlur(contrast, (3, 3), 0)\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY, blockSize=25, C=10\n",
    "    )\n",
    "    thresh = cv2.bitwise_not(thresh)\n",
    "    return thresh\n",
    "\n",
    "reader = easyocr.Reader(['vi', 'en'])\n",
    "\n",
    "def extract_text_from_preprocessed(img):\n",
    "    if img is None:\n",
    "        return []\n",
    "    return reader.readtext(img, detail=0)\n",
    "\n",
    "def fix_common_ocr_errors(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\b1o\\b', '10', text)\n",
    "    text = re.sub(r'\\buong\\b', 'uống', text)\n",
    "    text = re.sub(r'[;,_]', ' ', text)\n",
    "    text = re.sub(r'[-–—]', '-', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def contains_medicine_name(text, keywords):\n",
    "    text = text.lower()\n",
    "    for kw in keywords:\n",
    "        if kw in text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def extract_medicine_lines(lines, keywords):\n",
    "    results = []\n",
    "    for line in lines:\n",
    "        line_clean = line.strip()\n",
    "        if len(line_clean) < 6:\n",
    "            continue\n",
    "        line_fixed = fix_common_ocr_errors(line_clean)\n",
    "\n",
    "        has_unit = re.search(r'\\b(\\d+(mg|ml|g)|viên|gói|vỉ)\\b', line_fixed)\n",
    "        starts_with_num = re.match(r'^\\d+\\.', line_fixed)\n",
    "        has_med_name = contains_medicine_name(line_fixed, keywords)\n",
    "\n",
    "        if has_med_name or has_unit or starts_with_num:\n",
    "            results.append(line_fixed)\n",
    "    return results\n",
    "\n",
    "df_pics['preprocessed'] = df_pics['abs_path'].apply(preprocess_image)\n",
    "df_pics['ocr_text'] = df_pics['preprocessed'].apply(extract_text_from_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_pics[['path', 'ocr_text']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py313 (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
